# 클라우드 인프라 및 컨테이너 관리

## 관리 포인트

1. EC2 서버 3대를 이용해 쿠버네티스 클러스터 구축
2. MSA 아키텍처를 고려한 서비스 배포
3. AWS 네트워크 및 보안 구성을 통한 안전한 운영

---

### 1. AWS 인프라 설계

EC2 서버 2대의 역할 구분


| 역할 | 설명                             |
| ---- | -------------------------------- |
| 1대  | Control Plane (Master)           |
| 2대  | Worker Nodes (애플리케이션 실행) |

#### Control Plane (Master Node)

* kube-apiserver, etcd, controller-manager, scheduler 실행
* kubectl을 통해 관리
* 장애 시 복구할 수 있도록 관리

#### Worker Nodes

* API Gateway, Eureka Service, Config Service, 기능 서비스 등을 컨테이너로 배포
* AWS Auto Scaling Group을 설정해 필요 시 확장할 수 있도록 구조 설계

---

### 2. 쿠버네티스 클러스터 구축

#### 배포 방식

1. K3s (경량 쿠버네티스)
   1. EC2 3대에서 부담없이 실행 가능
   2. 설정이 간단하고, 성능 최적화 가능
2. Kebeadm (공식 배포 도구)
   1. 일반적인 쿠버네티스 설치 방법
   2. 마스터 노드 1대, 워커 노드 2대 구성

k3s -> 필요시 Kebeadm ..?

---

### 3. 리소스 관리

NameSpace 분리


| 네임스페이스 | 포함 서비스                         |
| ------------ | ----------------------------------- |
| platform     | API Gateway, Eureka, Config Service |
| services     | 회원, 인증, QnA 서비스              |
| monitoring   | Prometheus, Grafana                 |
| storage      | S3 또는 DB 관련 서비스              |

장애가 발생해도 영향을 최소화 하는 방향

모니터링 및 관리가 쉬워짐

---

### 4. 네트워크 및 보안 설정

##### VPC 및 보안 그룹

VPC 서브넷 분리

* Public Subnet -> API Gateway 등 외부 접근 서비스
* Private Subnet -> DB 및 내부 API 통신

보안 그룹 (Security Group) 설정

- EC2 접근:SSH는 특정 IP에서만 허용
- 컨테이너 네트워크: 서비스 간 통신 허용, 외부 접근 제한

IAM 보안 정책

- EC2 관리는 Root 계정이 아닌 IAM 사용자로 제한
- IAM User는 MFA 필수
- EKS 또는 K3s가 IAM Role을 사용해 AWS 리소스 접근 제한

---

### 5. 컨테이너 개수

#### 5-1. 컨테이너 개수 결정 기준

1. 기본적으로 서비스당 1개 이상 배포
2. 부하가 많거나 병렬 처리가 필요한 서비스는 추가 컨테이너 배포
3. API GateWay나 Eureka 같은 서비스는 최소 2개 이상 유지 (가용성)
4. CPU & 메모리 사용량을 기반으로 Scale Up/Down 가능하도록 설정

#### 5-2. 서비스별 컨테이너 개수 예측


| 서비스          | 컨테이너 개수 | 역할           |
| --------------- |---------|--------------|
| API GateWay     | 2       | 클라이언트 요청 라우팅 |
| Eureka Service  | 2       | 서비스 디스커버리    |
| Config Service  | 1       | 설정 관리        |
| 스토리지 서비스 | 2       | DB           |
| 알림 서비스     | 2       |              |
| 회원 서비스     | 2       |              |
| 인증 서비스     | 2       |              |
| QnA 서비스      | 2       |              |
| Prometheus      | 1       | 메트릭 수집       |
| Grafana         | 1       | 모니터링 대시보드    |

#### 5-3. 컨테이너 배포 전략

1. 각 서비스는 최소 1개 이상의 컨테이너 유지
2. API Gateway, Eureka, 인증 서비스는 최소 2개 이상 유지하며 장애 발생 시 대응
3. Prometheus & Grafana는 1개만 배포
4. EC2의 리소스가 부족하면 Worker Node를 추가하거나 Horizontal Scaling 가능하도록 설정

### 5-4. Auto Scaling 고려

부하에 따라 컨테이너 수 자동 조절

HPA (Horizontal Pod Autoscaler) 사용 가능
CPU 사용량이 70% 이상이면 최대 5개까지 컨테이너 자동 확장

```yaml
apiVersion: autoscaling/v2beta2
kind: HorizontalPodAutoscaler
metadata:
  name: user-service-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: user-service
  minReplicas: 2
  maxReplicas: 5
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70

```

### 6. 배포 및 운영

#### 배포 전략

##### 1. **Rolling Update (롤링 업데이트)**

- **특징**: 기존 버전을 점진적으로 새로운 버전으로 교체하여 **무중단 배포**를 보장
- **장점**: 서비스의 **다운타임**을 최소화하고, **빠른 롤백**이 가능
- **적용 시나리오**:
  - 새로운 버전의 애플리케이션을 **점진적으로 배포**하면서 트래픽을 관리
  - **AWS EC2**와 같은 환경에서 **서비스 무중단 업데이트**에 적합

##### 2. **Blue-Green Deployment (블루-그린 배포)**

- **특징**: 두 개의 환경(Blue, Green)을 두고, **새로운 버전의 환경**(Green)으로 트래픽을 전환하여 배포
- **장점**: **안전한 배포** 및 **빠른 롤백**이 가능
- **적용 시나리오**:
  - 서비스가 **새로운 버전으로 안정적으로 전환**되는지 검증 후 트래픽을 전환
  - 문제가 발생하면 **이전 버전**(Blue)으로 빠르게 되돌릴 수 있음

RollBack

1. 장애 발생 시 즉시 이전 버전으로 롤백 (kubectl rollout undo)


#### 모니터링 시스템

Prometheus + Grafana

- CPU, Memory 사용량, 트래픽 모니터링
- 특정 횟수 이상 에러 발생 시 Slack/WebHook 알림
